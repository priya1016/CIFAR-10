{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn, optim\nfrom torchvision import transforms, models\nimport torchvision\n\nimport time\nimport timeit","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-03T01:18:23.092696Z","iopub.execute_input":"2022-05-03T01:18:23.092984Z","iopub.status.idle":"2022-05-03T01:18:23.100143Z","shell.execute_reply.started":"2022-05-03T01:18:23.092950Z","shell.execute_reply":"2022-05-03T01:18:23.099376Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Ensure that the output of this 2 line code is GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device.type}\")\n\n# TRAIN_DIR = \"../input/cifar10-pngs-in-folders/cifar10/train\"\n# VALID_DIR = \"../input/cifar10-pngs-in-folders/cifar10/test/\"\n\n# train_dataset = torchvision.datasets.ImageFolder(root=TRAIN_DIR)\n# valid_dataset = torchvision.datasets.ImageFolder(root=VALID_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T00:32:17.408963Z","iopub.execute_input":"2022-05-03T00:32:17.409777Z","iopub.status.idle":"2022-05-03T00:32:17.475598Z","shell.execute_reply.started":"2022-05-03T00:32:17.409736Z","shell.execute_reply":"2022-05-03T00:32:17.474848Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = \"../input/cifar10-pngs-in-folders/cifar10/train\"\nVALID_DIR = \"../input/cifar10-pngs-in-folders/cifar10/test/\"\n\ntrain_dataset = torchvision.datasets.ImageFolder(root=TRAIN_DIR)\nvalid_dataset = torchvision.datasets.ImageFolder(root=VALID_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T00:33:39.072610Z","iopub.execute_input":"2022-05-03T00:33:39.072901Z","iopub.status.idle":"2022-05-03T00:34:21.417601Z","shell.execute_reply.started":"2022-05-03T00:33:39.072851Z","shell.execute_reply":"2022-05-03T00:34:21.416791Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_transforms = transforms.Compose(\n    [#transforms.Resize([IMAGE_SIZE, IMAGE_SIZE]),\n     transforms.ToTensor(),\n     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n)\n\nBATCH_SIZE = 128\n\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=data_transforms)\n\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=data_transforms)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                                          shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                                         shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T02:04:49.732525Z","iopub.execute_input":"2022-05-03T02:04:49.732774Z","iopub.status.idle":"2022-05-03T02:05:00.732938Z","shell.execute_reply.started":"2022-05-03T02:04:49.732745Z","shell.execute_reply":"2022-05-03T02:05:00.732199Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 32\n\ngen = iter(train_dataset)\n\n# data_transforms = transforms.Compose(\n#     [#transforms.Resize([IMAGE_SIZE, IMAGE_SIZE]),\n#      transforms.ToTensor(),\n#      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n# )\n\n# train_dataset = torchvision.datasets.ImageFolder(\n#     root=TRAIN_DIR, transform=data_transforms\n# )\n# valid_dataset = torchvision.datasets.ImageFolder(\n#     root=VALID_DIR, transform=data_transforms\n# )\nimg, target = next(iter(train_dataset))\nprint(f\"Image data type: {type(img)}\")\nprint(f\"     Image size: {img.shape}\")\n\n\n# BATCH_SIZE = 128\n\n# train_loader = torch.utils.data.DataLoader(\n#     train_dataset,  # our raw data\n#     batch_size=BATCH_SIZE,  # the size of batches the dataloader returns\n#     shuffle=True,  # shuffle our data before batching\n#     drop_last=False,  # not dropping the last batch even if it's smaller than batch_size\n# )\n\n# valid_loader = torch.utils.data.DataLoader(\n#     valid_dataset,  # our raw validation data\n#     batch_size=BATCH_SIZE,  # the size of batches the dataloader returns\n#     shuffle=True,\n# )","metadata":{"execution":{"iopub.status.busy":"2022-05-03T00:34:21.419443Z","iopub.execute_input":"2022-05-03T00:34:21.419939Z","iopub.status.idle":"2022-05-03T00:34:30.133485Z","shell.execute_reply.started":"2022-05-03T00:34:21.419900Z","shell.execute_reply":"2022-05-03T00:34:30.132770Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Method 1: SimpleCNN","metadata":{}},{"cell_type":"code","source":"class simple_CNN(torch.nn.Module):\n    def __init__(\n        self,\n    ):\n        super().__init__()\n        self.main = torch.nn.Sequential(\n            torch.nn.Conv2d(\n                in_channels=3, out_channels=15, kernel_size=(3, 3), padding=1\n            ),  # 1st CNN layer\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d((2, 2)),\n            nn.Dropout(0.2),\n            torch.nn.Conv2d(\n                in_channels=15, out_channels=4, kernel_size=(3, 3), padding=1\n            ),  # 2nd CNN layer\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d((2, 2)),\n            nn.Dropout(0.2),\n            torch.nn.Flatten(),\n            torch.nn.Linear(256, 128),\n            torch.nn.ReLU(),\n            torch.nn.Linear(128, 64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64, 10),\n        )\n\n    def forward(self, x):\n        out = self.main(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:14:21.427346Z","iopub.execute_input":"2022-05-03T01:14:21.427597Z","iopub.status.idle":"2022-05-03T01:14:21.436705Z","shell.execute_reply.started":"2022-05-03T01:14:21.427568Z","shell.execute_reply":"2022-05-03T01:14:21.436036Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def trainer(\n    model, criterion, optimizer, trainloader, validloader, epochs=5, verbose=True\n):\n    \"\"\"Simple training wrapper for PyTorch network.\"\"\"\n\n    train_loss, valid_loss, valid_accuracy, train_accuracy = [], [], [], []\n    for epoch in range(epochs):\n        train_batch_loss = 0\n        train_batch_acc = 0\n        valid_batch_loss = 0\n        valid_batch_acc = 0\n        \n        start = time.process_time()  \n        \n        # Training\n        print(f\"Training for epoch {epoch+1} started\")\n        for X, y in trainloader:\n            X, y = X.to(device), y.to(device)\n            optimizer.zero_grad()  # Zero all the gradients w.r.t. parameters\n            y_hat = model(X)  # initialize model\n            _, y_hat_labels = torch.softmax(y_hat, dim=1).topk(\n                1, dim=1\n            )  # Assigning class label to prediction\n            loss = criterion(y_hat, y)  # Calculate loss based on output\n            loss.backward()  # Calculate gradients w.r.t. parameters\n            optimizer.step()  # Update parameters\n            train_batch_loss += loss.item()  # Add loss for this batch to running total\n            train_batch_acc += (\n                (y_hat_labels.squeeze() == y).type(torch.float32).mean().item()\n            )\n        train_loss.append(train_batch_loss / len(trainloader))\n        train_accuracy.append(\n            train_batch_acc / len(trainloader)\n        )  # accuracy of the train set\n        \n        print(f\"Training for epoch {epoch+1} ended in {round(time.process_time() - start, 2)} seconds\")\n        \n        # Validation\n        model.eval()\n        with torch.no_grad():  # this stops pytorch doing computational graph stuff under-the-hood and saves memory and time\n            for X, y in validloader:\n                X, y = X.to(device), y.to(device)\n                y_hat = model(X)\n                _, y_hat_labels = torch.softmax(y_hat, dim=1).topk(1, dim=1)\n                loss = criterion(y_hat, y)\n                valid_batch_loss += loss.item()\n                valid_batch_acc += (\n                    (y_hat_labels.squeeze() == y).type(torch.float32).mean().item()\n                )\n        valid_loss.append(valid_batch_loss / len(validloader))\n        valid_accuracy.append(\n            valid_batch_acc / len(validloader)\n        )  # accuracy of the valid set\n        model.train()\n\n        # Print progress\n        if verbose:\n            print(\n                f\"Epoch {epoch + 1}:\",\n                f\"Train Loss: {train_loss[-1]:.3f}.\",\n                f\"Valid Loss: {valid_loss[-1]:.3f}.\",\n                f\"Train Accuracy: {train_accuracy[-1]:.2f}.\",\n                f\"Valid Accuracy: {valid_accuracy[-1]:.2f}.\",\n            )\n        print(\"\\n\")\n    results = {\n        \"train_loss\": train_loss,\n        \"valid_loss\": valid_loss,\n        \"train_accuracy\": train_accuracy,\n        \"valid_accuracy\": valid_accuracy,\n    }\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-05-03T00:35:33.807745Z","iopub.execute_input":"2022-05-03T00:35:33.808424Z","iopub.status.idle":"2022-05-03T00:35:33.823015Z","shell.execute_reply.started":"2022-05-03T00:35:33.808385Z","shell.execute_reply":"2022-05-03T00:35:33.822177Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(2018)\n\nmodel = simple_CNN()\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n\nstart = timeit.default_timer()\n  \nresults = trainer(model, criterion, optimizer, train_loader, valid_loader, epochs=15)\n\nstop = timeit.default_timer()\n\nprint('Total Time Taken: ', stop - start)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:18:27.603546Z","iopub.execute_input":"2022-05-03T01:18:27.603791Z","iopub.status.idle":"2022-05-03T01:31:26.814068Z","shell.execute_reply.started":"2022-05-03T01:18:27.603762Z","shell.execute_reply":"2022-05-03T01:31:26.813350Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Densenet 121: 120 CNN layers!!!!!!!","metadata":{}},{"cell_type":"code","source":"densenet = models.densenet161(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T00:34:30.134907Z","iopub.execute_input":"2022-05-03T00:34:30.135406Z","iopub.status.idle":"2022-05-03T00:34:37.888450Z","shell.execute_reply.started":"2022-05-03T00:34:30.135367Z","shell.execute_reply":"2022-05-03T00:34:37.887726Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# densenet = models.densenet121(pretrained=True)\n\nfor (\n    param\n) in densenet.parameters():  # Freeze parameters which are not updated during training\n    param.requires_grad = False\n    \n# Unfreeze one block(combinations of CNN layers), parameters are optimized during training using CIFAR-10 datapoints\nfor param in densenet.features.denseblock4.parameters():\n    param.requires_grad = True\n    \nnew_layers = nn.Sequential(\n    nn.Linear(2208, 128),\n    nn.ReLU(),\n    nn.Linear(128, 64),\n    nn.ReLU(),\n    nn.Linear(64, 10),\n#     nn.Linear(1024, 512),\n#     nn.ReLU(),\n#     nn.Linear(512, 256),\n#     nn.ReLU(),\n#     nn.Linear(256, 128),\n#     nn.ReLU(),\n#     nn.Linear(128, 64),\n#     nn.ReLU(),\n#     nn.Linear(64, 10)\n)\ndensenet.classifier = new_layers\n\ntorch.manual_seed(2018)\ndensenet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(densenet.parameters(), lr=0.01)\n\nstart = timeit.default_timer()\nresults = trainer(densenet, criterion, optimizer, train_loader, valid_loader, epochs=20)\nstop = timeit.default_timer()\n\nprint('Total Time Taken: ', stop - start)\n# optimizer = optim.SGD(resnet.parameters(), lr=0.01, momentum=0.9, nesterov=False, weight_decay=(0.01/25))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:38:03.188032Z","iopub.execute_input":"2022-05-03T01:38:03.188306Z","iopub.status.idle":"2022-05-03T02:03:48.173346Z","shell.execute_reply.started":"2022-05-03T01:38:03.188277Z","shell.execute_reply":"2022-05-03T02:03:48.172546Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"classes = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\ntest_accuracy = {}\n\nwith torch.no_grad():\n    n_correct = 0\n    n_samples = 0\n    n_class_correct = [0 for i in range(10)]\n    n_class_samples = [0 for i in range(10)]\n    for images, labels in valid_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = densenet(images)\n\n        _, predicted = torch.max(outputs, 1)\n        n_samples += labels.size(0)\n        n_correct += (predicted == labels).sum().item()\n        \n        for i in range(labels.size(0)):\n            label = labels[i]\n            pred = predicted[i]\n            if (label == pred):\n                n_class_correct[label] += 1\n            n_class_samples[label] += 1\n\n    acc = 100.0 * n_correct / n_samples\n    print(f'Accuracy of the network: {acc} %')\n\n    for i in range(10):\n        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n        test_accuracy[classes[i]] = f\"{round(acc, 2)} %\"","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:12:42.956493Z","iopub.execute_input":"2022-05-03T01:12:42.956753Z","iopub.status.idle":"2022-05-03T01:12:55.187072Z","shell.execute_reply.started":"2022-05-03T01:12:42.956724Z","shell.execute_reply":"2022-05-03T01:12:55.186330Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(test_accuracy, index=['Accuracy']).T","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:13:03.203620Z","iopub.execute_input":"2022-05-03T01:13:03.203977Z","iopub.status.idle":"2022-05-03T01:13:03.225917Z","shell.execute_reply.started":"2022-05-03T01:13:03.203940Z","shell.execute_reply":"2022-05-03T01:13:03.225011Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}